{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hyperparameter Tuning Explained**\n",
    "\n",
    "## **1. What is Hyperparameter Tuning?**  \n",
    "Hyperparameter tuning is the process of **choosing the best set of hyperparameters** for a machine learning model to improve its performance. Unlike model parameters (learned from data), hyperparameters are set **before training** and directly affect the learning process.\n",
    "\n",
    "## **2. Examples of Hyperparameters**  \n",
    "- **Learning Rate (α):** Controls the step size in gradient descent.  \n",
    "- **Number of Hidden Layers & Neurons:** Defines the architecture of neural networks.  \n",
    "- **Batch Size:** Determines how many samples are processed before updating weights.  \n",
    "- **Number of Trees (for Random Forest, XGBoost):** Controls the number of decision trees in ensemble methods.  \n",
    "- **Regularization Strength (λ):** Prevents overfitting by penalizing large weights.  \n",
    "- **Dropout Rate:** Specifies the fraction of neurons to drop during training in deep learning.  \n",
    "\n",
    "## **3. Methods for Hyperparameter Tuning**  \n",
    "\n",
    "### **(i) Grid Search**  \n",
    "- Tries **all possible combinations** of hyperparameters from a predefined set. \n",
    "\n",
    "- **Example:**  \n",
    "  ```python\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  \n",
    "  param_grid = {\n",
    "      'n_estimators': [10, 50, 100],\n",
    "      'max_depth': [5, 10, 20]\n",
    "  }\n",
    "  ```python\n",
    "  model = RandomForestClassifier()\n",
    "  grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "  print(grid_search.best_params_)\n",
    "    ```\n",
    "\n",
    "- Pros: Simple, guarantees finding the best combination.\n",
    "- Cons: Computationally expensive, especially with many parameters.\n",
    "\n",
    "###  **(ii) Random Search**\n",
    "- Randomly selects hyperparameter combinations and evaluates them.\n",
    "- Pros: Faster than Grid Search.\n",
    "- Cons: May not explore the optimal combination.\n",
    "    ```python\n",
    "        from sklearn.model_selection import RandomizedSearchCV\n",
    "        from scipy.stats import randint\n",
    "\n",
    "        param_dist = {\n",
    "            'n_estimators': randint(10, 200),\n",
    "            'max_depth': randint(5, 50)\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier()\n",
    "        random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5, random_state=42)\n",
    "        random_search.fit(X_train, y_train)\n",
    "        print(random_search.best_params_)\n",
    "    ```\n",
    "\n",
    "### **(iii) Bayesian Optimization**\n",
    "- Uses probabilistic models to predict promising hyperparameters and optimize efficiently.\n",
    "- Example: Implemented using the optuna or scikit-optimize library.\n",
    "\n",
    "### **(iv) Genetic Algorithms (Evolutionary Search)**\n",
    "- Inspired by natural selection, it evolves the best set of hyperparameters over generations.\n",
    "### **(v) Hyperband**\n",
    "- Optimizes hyperparameters based on resource allocation, improving efficiency.\n",
    "\n",
    "### Best Practices for Hyperparameter Tuning\n",
    "- Start with Random Search or Bayesian Optimization for efficiency.\n",
    "- Use cross-validation (e.g., cv=5) to ensure robustness.\n",
    "- Reduce the search space by experimenting with a smaller range of values.\n",
    "- Monitor training time and computational cost.\n",
    "- Consider using automated tuning tools like Optuna, Hyperopt, or AutoML.\n",
    "\n",
    "### Conclusion\n",
    "- Hyperparameter tuning is crucial for optimizing model performance. While Grid Search ensures optimal results, Random Search, Bayesian Optimization, and Genetic Algorithms provide efficient alternatives. The choice depends on the problem, computational resources, and time constraints.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
