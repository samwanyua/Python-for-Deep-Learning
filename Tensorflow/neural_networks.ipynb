{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks (ANN)  \n",
    "\n",
    "###  What is an Artificial Neural Network?  \n",
    "An **Artificial Neural Network (ANN)** is a computational model inspired by **biological neural networks** in the human brain. It consists of layers of **interconnected neurons** that process information and learn patterns from data.\n",
    "\n",
    "---\n",
    "\n",
    "### Structure of an ANN  \n",
    "An ANN typically consists of three main types of layers:\n",
    "\n",
    "1. **Input Layer**   \n",
    "   - Takes raw input features (e.g., images, text, or numbers).  \n",
    "   - Passes them to the next layer.\n",
    "\n",
    "2. **Hidden Layers**  \n",
    "   - Perform computations and extract patterns.  \n",
    "   - Each neuron applies a mathematical transformation (e.g., weighted sum + activation function).\n",
    "\n",
    "3. **Output Layer**  \n",
    "   - Produces the final result (e.g., classification label or predicted value).\n",
    "\n",
    "---\n",
    "\n",
    "### How an ANN Works?  \n",
    "1. **Forward Propagation:**  \n",
    "   - Inputs pass through the network layer by layer.  \n",
    "   - Neurons apply weights, biases, and activation functions.  \n",
    "\n",
    "2. **Loss Calculation:**  \n",
    "   - The network compares predictions to actual values using a **loss function** (e.g., MSE, Cross-Entropy).  \n",
    "\n",
    "3. **Backward Propagation (Backpropagation):**  \n",
    "   - Computes **gradients** using differentiation.  \n",
    "   - Adjusts weights via **Gradient Descent** (or other optimizers like Adam).  \n",
    "\n",
    "4. **Training Iteration (Epochs):**  \n",
    "   - The process repeats multiple times until the model learns effectively.\n",
    "\n",
    "---\n",
    "### Common Activation Functions  \n",
    "| Function   | Formula | Usage |\n",
    "|------------|---------|--------|\n",
    "| **Sigmoid** | \\( \\sigma(x) = \\frac{1}{1 + e^{-x}} \\) | Outputs probability (0 to 1) |\n",
    "| **ReLU** | \\( f(x) = \\max(0, x) \\) | Handles non-linearity, prevents vanishing gradient |\n",
    "| **Softmax** | \\( \\frac{e^x}{\\sum e^x} \\) | Used for multi-class classification |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ›  Applications of ANN  \n",
    "- Image Recognition (e.g., Face Recognition)  \n",
    "- Natural Language Processing (e.g., Chatbots)  \n",
    "- Time Series Prediction (e.g., Stock Market Forecasting)  \n",
    "- Healthcare (e.g., Disease Diagnosis)  \n",
    "\n",
    "---\n",
    "\n",
    "### Advantages of ANN  \n",
    "âœ” **Learns complex patterns** automatically.  \n",
    "âœ” **Can handle large datasets** and unstructured data (e.g., images, text).  \n",
    "âœ” **Adaptable** to various domains (vision, speech, NLP).  \n",
    "\n",
    "###  Challenges of ANN  \n",
    "- Requires **a lot of data** to perform well.  \n",
    "- Training can be **computationally expensive**.  \n",
    "- Difficult to interpret (often called a **\"black box\"** model).  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = np.array([[0,0],[0,1],[1,0],[1,1]],dtype=np.float32)\n",
    "y_train_data = np.array([[0],[1],[0],[0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in each layer\n",
    "n_input = 2 # no. of features\n",
    "n_hidden = 4 # number of hidden units\n",
    "n_output = 1 # number of output units\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholder for input and output\n",
    "X = tf.Variable(tf.random.normal([1, n_input]), dtype=tf.float32)\n",
    "y = tf.Variable(tf.random.normal([1, n_output]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
