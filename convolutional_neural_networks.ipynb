{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "CNN are DL models designed for image recognition and classifications. Consists of multiple layers including convolutional, pooling and fully connected layers to learn spatial features from images\n",
    "\n",
    "Key Components:\n",
    "- Convolutionals layers that appy filters(kernels) to detect local features. Output is the weighted sum of input and bias through the activation function.\n",
    "-Activation functions like ReLU introduce non-linearity for complex pattern learning\n",
    "- Pooling layers reduce spatial dimensions for computational efficiency.\n",
    "- Fully connected layers that learn global patterns and produce class probabilities using softmax activation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 552874 (2.11 MB)\n",
      "Trainable params: 551722 (2.10 MB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_models():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=(32,32,3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(32,(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), activation='relu', padding='same', input_shape=(32,32,3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Conv2D(128,(3,3), activation='relu', padding='same', input_shape=(32,32,3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = create_cnn_models()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 199s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 14:48:39.468415: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 491520000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 255s 401ms/step - loss: 1.8482 - accuracy: 0.3715 - val_loss: 1.4537 - val_accuracy: 0.4806\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 256s 409ms/step - loss: 1.2730 - accuracy: 0.5416 - val_loss: 1.1565 - val_accuracy: 0.5849\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 243s 389ms/step - loss: 1.0790 - accuracy: 0.6166 - val_loss: 0.9200 - val_accuracy: 0.6730\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 225s 359ms/step - loss: 0.9629 - accuracy: 0.6596 - val_loss: 0.8285 - val_accuracy: 0.7014\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 203s 325ms/step - loss: 0.8728 - accuracy: 0.6965 - val_loss: 0.7484 - val_accuracy: 0.7365\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 238s 381ms/step - loss: 0.8191 - accuracy: 0.7154 - val_loss: 0.8712 - val_accuracy: 0.6953\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 242s 388ms/step - loss: 0.7681 - accuracy: 0.7326 - val_loss: 0.6987 - val_accuracy: 0.7540\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.7464"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "(train_images, train_labels), (test_images, test_labels)= cifar10.load_data()\n",
    "train_images = train_images.astype('float32')/ 255\n",
    "test_images = test_images.astype('float32')/255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
